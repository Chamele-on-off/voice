#!/usr/bin/env python3
"""
ZINDAKI TTS SERVICE - –ü–æ–ª–Ω–∞—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
–° –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –ø—Ä–æ–±–ª–µ–º—ã —Å–æ–∑–¥–∞–Ω–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤
"""

import os
import sys
import torch
import torchaudio
import tempfile
import time
import shutil
from datetime import datetime
from flask import Flask, request, jsonify, send_file, render_template
from flask_cors import CORS
from pydantic import BaseModel, ValidationError
import redis
from rq import Queue
from rq.job import Job
import threading
import atexit

# ========== –ù–ê–°–¢–†–û–ô–ö–ê –û–ö–†–£–ñ–ï–ù–ò–Ø ==========
os.environ['TORCH_HOME'] = '/app/cache'
os.environ['HF_HOME'] = '/app/cache'
os.environ['XDG_CACHE_HOME'] = '/app/cache'

# –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
os.makedirs('/app/cache/torch/hub', exist_ok=True)
os.makedirs('/app/temp_audio', exist_ok=True)

# ========== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø REDIS ==========
redis_conn = redis.Redis(
    host=os.getenv('REDIS_HOST', 'tts-redis'),
    port=int(os.getenv('REDIS_PORT', 6379)),
    db=1,
    socket_connect_timeout=10,
    socket_timeout=30,
    retry_on_timeout=True
)

# –û—á–µ—Ä–µ–¥—å –∑–∞–¥–∞—á
queue = Queue(connection=redis_conn, default_timeout=600)

# ========== –ù–ê–°–¢–†–û–ô–ö–ê FLASK ==========
app = Flask(__name__, template_folder='templates')
CORS(app, resources={r"/*": {"origins": "*"}})

# ========== –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï ==========
tts_models = {}
startup_time = datetime.now()

# ========== –ö–û–†–†–ï–ö–¢–ù–´–ï –ò–ú–ï–ù–ê –î–ò–ö–¢–û–†–û–í SILERO ==========
SPEAKER_MAPPING = {
    'ru': {
        'baya': 'baya_16khz',
        'kseniya': 'kseniya_16khz',
        'aidar': 'aidar_16khz',
        'irina': 'irina_16khz',
        'natasha': 'natasha_16khz',
        'ruslan': 'ruslan_16khz',
        'xenia': 'xenia_16khz',
        'random': 'random'
    },
    'en': {
        'en_0': 'en_0',           # Amy (female)
        'en_1': 'en_1',           # Eric (male)
        'en_2': 'en_2',           # Kyle (male)
        'en_3': 'en_3',           # Lucy (female)
        'en_4': 'en_4',           # Nancy (female)
        'en_5': 'en_5',           # Grace (female)
        'en_6': 'en_6',           # Anthony (male)
        'en_7': 'en_7',           # Emma (female)
        'en_8': 'en_8',           # Brian (male)
        'en_9': 'en_9',           # Jenny (female)
        'en_10': 'en_10',         # Chris (male)
        'en_11': 'en_11',         # Elizabeth (female)
        'en_12': 'en_12',         # George (male)
        'en_13': 'en_13',         # Linda (female)
        'en_14': 'en_14',         # Mark (male)
        'en_15': 'en_15',         # Mary (female)
        'en_16': 'en_16',         # Paul (male)
        'en_17': 'en_17',         # Sarah (female)
        'en_18': 'en_18',         # Steven (male)
        'en_19': 'en_19',         # Susan (female)
        'en_20': 'en_20',         # Thomas (male)
        'en_21': 'en_21',         # Victoria (female)
        'en_22': 'en_22',         # William (male)
        'en_23': 'en_23',         # Heather (female)
        'en_24': 'en_24',         # James (male)
        'en_25': 'en_25',         # Jennifer (female)
        'en_26': 'en_26',         # John (male)
        'en_27': 'en_27',         # Karen (female)
        'en_28': 'en_28',         # Michael (male)
        'en_29': 'en_29',         # Michelle (female)
        'en_30': 'en_30',         # Richard (male)
        'en_31': 'en_31',         # Sandra (female)
        'en_32': 'en_32',         # David (male)
        'en_33': 'en_33',         # Barbara (female)
        'en_34': 'en_34',         # Charles (male)
        'en_35': 'en_35',         # Margaret (female)
        'en_36': 'en_36',         # Joseph (male)
        'en_37': 'en_37',         # Dorothy (female)
        'en_38': 'en_38',         # Christopher (male)
        'en_39': 'en_39',         # Lisa (female)
        'en_40': 'en_40',         # Daniel (male)
        'en_41': 'en_41',         # Nancy (female) - duplicate name
        'en_42': 'en_42',         # Matthew (male)
        'en_43': 'en_43',         # Betty (female)
        'en_44': 'en_44',         # Anthony (male) - duplicate name
        'en_45': 'en_45',         # Helen (female)
        'en_46': 'en_46',         # Donald (male)
        'en_47': 'en_47',         # Carol (female)
        'en_48': 'en_48',         # Ronald (male)
        'en_49': 'en_49',         # Ruth (female)
        'en_50': 'en_50',         # Kevin (male)
        'en_51': 'en_51',         # Shirley (female)
        'en_52': 'en_52',         # Edward (male)
        'en_53': 'en_53',         # Deborah (female)
        'en_54': 'en_54',         # Jason (male)
        'en_55': 'en_55',         # Jessica (female)
        'en_56': 'en_56',         # Ryan (male)
        'en_57': 'en_57',         # Cynthia (female)
        'en_58': 'en_58',         # Jacob (male)
        'en_59': 'en_59',         # Angela (female)
        'en_60': 'en_60',         # Gary (male)
        'en_61': 'en_61',         # Melissa (female)
        'en_62': 'en_62',         # Nicholas (male)
        'en_63': 'en_63',         # Brenda (female)
        'en_64': 'en_64',         # Eric (male) - duplicate name
        'en_65': 'en_65',         # Pamela (female)
        'en_66': 'en_66',         # Jonathan (male)
        'en_67': 'en_67',         # Rebecca (female)
        'en_68': 'en_68',         # Stephen (male)
        'en_69': 'en_69',         # Sharon (female)
        'en_70': 'en_70',         # Larry (male)
        'en_71': 'en_71',         # Kathleen (female)
        'en_72': 'en_72',         # Justin (male)
        'en_73': 'en_73',         # Amy (female) - duplicate name
        'en_74': 'en_74',         # Brandon (male)
        'en_75': 'en_75',         # Anna (female)
        'en_76': 'en_76',         # Gregory (male)
        'en_77': 'en_77',         # Ruth (female) - duplicate name
        'en_78': 'en_78',         # Samuel (male)
        'en_79': 'en_79',         # Virginia (female)
        'en_80': 'en_80',         # Frank (male)
        'en_81': 'en_81',         # Katherine (female)
        'en_82': 'en_82',         # Raymond (male)
        'en_83': 'en_83',         # Christine (female)
        'en_84': 'en_84',         # Patrick (male)
        'en_85': 'en_85',         # Janet (female)
        'en_86': 'en_86',         # Jack (male)
        'en_87': 'en_87',         # Carolyn (female)
        'en_88': 'en_88',         # Dennis (male)
        'en_89': 'en_89',         # Catherine (female)
        'en_90': 'en_90',         # Jerry (male)
        'en_91': 'en_91',         # Frances (female)
        'en_92': 'en_92',         # Tyler (male)
        'en_93': 'en_93',         # Ann (female)
        'en_94': 'en_94',         # Aaron (male)
        'en_95': 'en_95',         # Joyce (female)
        'en_96': 'en_96',         # Jose (male)
        'en_97': 'en_97',         # Diane (female)
        'en_98': 'en_98',         # Henry (male)
        'en_99': 'en_99',         # Alice (female)
        'en_100': 'en_100',       # Adam (male)
        'en_101': 'en_101',       # Julia (female)
        'en_102': 'en_102',       # Willie (male)
        'en_103': 'en_103',       # Judy (female)
        'en_104': 'en_104',       # Nathan (male)
        'en_105': 'en_105',       # Marie (female)
        'en_106': 'en_106',       # Evan (male)
        'en_107': 'en_107',       # Beverly (female)
        'en_108': 'en_108',       # Christian (male)
        'en_109': 'en_109',       # Denise (female)
        'en_110': 'en_110',       # Austin (male)
        'en_111': 'en_111',       # Marilyn (female)
        'en_112': 'en_112',       # Billy (male)
        'en_113': 'en_113',       # Amber (female)
        'en_114': 'en_114',       # Bruce (male)
        'en_115': 'en_115',       # Madison (female)
        'en_116': 'en_116',       # Bryan (male)
        'en_117': 'en_117',       # Danielle (female)
        'en_118': 'en_118',       # Albert (male)
        'en_119': 'en_119',       # Rose (female)
        'en_120': 'en_120',       # Lawrence (male)
        'en_121': 'en_121',       # Sophia (female)
        'en_122': 'en_122',       # Dylan (male)
        'en_123': 'en_123',       # Olivia (female)
        'en_124': 'en_124',       # Zachary (male)
        'en_125': 'en_125',       # Grace (female) - duplicate name
        'en_126': 'en_126',       # Kyle (male) - duplicate name
        'en_127': 'en_127',       # Chloe (female)
        'en_128': 'en_128',       # Louis (male)
        'en_129': 'en_129',       # Hailey (female)
        'en_130': 'en_130',       # Wayne (male)
        'en_131': 'en_131',       # Gabriella (female)
        'en_132': 'en_132',       # Ethan (male)
        'en_133': 'en_133',       # Allison (female)
        'en_134': 'en_134',       # Randy (male)
        'en_135': 'en_135',       # Lily (female)
        'en_136': 'en_136',       # Philip (male)
        'en_137': 'en_137',       # Megan (female)
        'en_138': 'en_138',       # Harry (male)
        'en_139': 'en_139',       # Savannah (female)
        'en_140': 'en_140',       # Vincent (male)
        'en_141': 'en_141',       # Alyssa (female)
        'en_142': 'en_142',       # Noah (male)
        'en_143': 'en_143',       # Haley (female)
        'en_144': 'en_144',       # Shawn (male)
        'en_145': 'en_145',       # Stella (female)
        'en_146': 'en_146',       # Connor (male)
        'en_147': 'en_147',       # Penelope (female)
        'en_148': 'en_148',       # Carlos (male)
        'en_149': 'en_149',       # Natalie (female)
    },
    'de': {
        'eva_k': 'eva_k',
        'karlsson': 'karlsson'
    },
    'es': {
        'es_0': 'es_0',
        'es_1': 'es_1'
    },
    'fr': {
        'fr_0': 'fr_0',
        'fr_1': 'fr_1'
    }
}

# ========== –ú–û–î–ï–õ–¨ –ó–ê–ü–†–û–°–ê ==========
class TTSRequest(BaseModel):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥—è—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
    text: str
    language: str = 'ru'
    speaker: str = 'baya'
    sample_rate: int = 16000
    speed: float = 1.0
    
    class Config:
        extra = 'forbid'

# ========== –§–£–ù–ö–¶–ò–Ø –ó–ê–ì–†–£–ó–ö–ò –ú–û–î–ï–õ–ò ==========
def load_tts_model(language='ru', user_speaker='baya'):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å Silero TTS –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é
    """
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–ª—é—á –¥–ª—è –∫—ç—à–∞
    model_key = f"{language}_{user_speaker}"
    
    if model_key not in tts_models:
        print(f"üì• –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å TTS: {language}/{user_speaker}")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–º—è –¥–∏–∫—Ç–æ—Ä–∞
        if language in SPEAKER_MAPPING and user_speaker in SPEAKER_MAPPING[language]:
            correct_speaker = SPEAKER_MAPPING[language][user_speaker]
        else:
            # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if language == 'ru':
                correct_speaker = 'baya_16khz'
            else:
                correct_speaker = user_speaker
        
        print(f"   –ò—Å–ø–æ–ª—å–∑—É—é –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–º—è: {correct_speaker}")
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∫—ç—à–∞
        torch.hub.set_dir('/app/cache/torch/hub')
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            result = torch.hub.load(
                repo_or_dir='snakers4/silero-models',
                model='silero_tts',
                language=language,
                speaker=correct_speaker,
                force_reload=False,
                trust_repo=True,
                verbose=False
            )
            
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({len(result)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤)")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            tts_models[model_key] = {
                'model': result[0],          # –ú–æ–¥–µ–ª—å TTS
                'symbols': result[1],        # –ê–ª—Ñ–∞–≤–∏—Ç/—Å–∏–º–≤–æ–ª—ã
                'sample_rate': result[2],    # –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
                'example_text': result[3],   # –ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞
                'apply_tts': result[4],      # –§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                'correct_speaker': correct_speaker,
                'device': torch.device('cpu'),
                'loaded_at': datetime.now().isoformat()
            }
            
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ CPU
            tts_models[model_key]['model'].to(tts_models[model_key]['device'])
            
            print(f"   Sample rate: {result[2]} Hz")
            print(f"   –ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞: {result[3][:50]}...")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise
    
    return tts_models[model_key]

# ========== –§–£–ù–ö–¶–ò–Ø –ì–ï–ù–ï–†–ê–¶–ò–ò –ê–£–î–ò–û ==========
def generate_audio(text, language, speaker, sample_rate, speed=1.0):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞
    –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è WAV —Ñ–∞–π–ª–æ–≤
    """
    try:
        start_time = time.time()
        
        print(f"\nüéµ –ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∞—É–¥–∏–æ")
        print(f"   –Ø–∑—ã–∫: {language}, –ì–æ–ª–æ—Å: {speaker}")
        print(f"   –¢–µ–∫—Å—Ç: '{text[:100]}{'...' if len(text) > 100 else ''}'")
        print(f"   –î–ª–∏–Ω–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –°–∫–æ—Ä–æ—Å—Ç—å: {speed}x")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ –∫—ç—à–∞
        model_info = load_tts_model(language, speaker)
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –º–æ–¥–µ–ª–∏
        model = model_info['model']
        symbols = model_info['symbols']
        target_sample_rate = model_info['sample_rate']
        apply_tts_func = model_info['apply_tts']
        device = model_info['device']
        
        print(f"   üîä –ò—Å–ø–æ–ª—å–∑—É—é –≥–æ–ª–æ—Å: {model_info['correct_speaker']}")
        print(f"   üéöÔ∏è  –ß–∞—Å—Ç–æ—Ç–∞: {target_sample_rate} Hz")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ
        audio_result = apply_tts_func(
            texts=[text],           # –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤
            model=model,
            sample_rate=target_sample_rate,
            symbols=symbols,
            device=device
        )
        
        # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê
        print(f"   üìä –¢–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {type(audio_result)}")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ —Ç–µ–Ω–∑–æ—Ä
        audio_tensor = None
        
        # 1. –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç - —Å–ø–∏—Å–æ–∫
        if isinstance(audio_result, list):
            print(f"   üìä –î–ª–∏–Ω–∞ —Å–ø–∏—Å–∫–∞: {len(audio_result)}")
            if len(audio_result) == 0:
                raise ValueError("apply_tts –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫")
            
            first_element = audio_result[0]
            print(f"   üìä –¢–∏–ø –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞: {type(first_element)}")
            
            if isinstance(first_element, torch.Tensor):
                audio_tensor = first_element
                print(f"   ‚úÖ –ò—Å–ø–æ–ª—å–∑—É—é —Ç–µ–Ω–∑–æ—Ä –∏–∑ —Å–ø–∏—Å–∫–∞")
            elif hasattr(first_element, 'numpy'):
                audio_tensor = torch.from_numpy(first_element.numpy())
                print(f"   ‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –∏–∑ numpy")
            else:
                try:
                    audio_tensor = torch.tensor(first_element, dtype=torch.float32)
                    print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω —Ç–µ–Ω–∑–æ—Ä –∏–∑ –¥–∞–Ω–Ω—ã—Ö")
                except:
                    raise ValueError(f"–ù–µ –º–æ–≥—É –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —ç–ª–µ–º–µ–Ω—Ç –≤ —Ç–µ–Ω–∑–æ—Ä: {type(first_element)}")
        
        # 2. –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞–ø—Ä—è–º—É—é —Ç–µ–Ω–∑–æ—Ä
        elif isinstance(audio_result, torch.Tensor):
            audio_tensor = audio_result
            print(f"   ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç - –Ω–∞–ø—Ä—è–º—É—é —Ç–µ–Ω–∑–æ—Ä")
        
        # 3. –ï—Å–ª–∏ —ç—Ç–æ numpy array
        elif hasattr(audio_result, '__array__'):
            import numpy as np
            audio_tensor = torch.from_numpy(np.array(audio_result, dtype=np.float32))
            print(f"   ‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –∏–∑ numpy array")
        
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {type(audio_result)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ —Ç–µ–Ω–∑–æ—Ä
        if audio_tensor is None:
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞—É–¥–∏–æ —Ç–µ–Ω–∑–æ—Ä")
        
        # –ü–†–û–í–ï–†–ö–ê –ò –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –¢–ï–ù–ó–û–†–ê
        print(f"   üîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–Ω–∑–æ—Ä–∞...")
        print(f"   üìê –ò—Å—Ö–æ–¥–Ω—ã–π shape: {audio_tensor.shape}")
        print(f"   üéõÔ∏è  –ò—Å—Ö–æ–¥–Ω—ã–π dtype: {audio_tensor.dtype}")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ float32 –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if audio_tensor.dtype != torch.float32:
            print(f"   üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—é –≤ float32")
            audio_tensor = audio_tensor.to(torch.float32)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π
        max_val = torch.max(torch.abs(audio_tensor))
        print(f"   üìä –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∞–±—Å–æ–ª—é—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {max_val.item()}")
        
        if max_val > 1.0:
            print(f"   üîÑ –ù–æ—Ä–º–∞–ª–∏–∑—É—é –∑–Ω–∞—á–µ–Ω–∏—è (–¥–µ–ª—é –Ω–∞ {max_val.item():.3f})")
            audio_tensor = audio_tensor / max_val
        elif max_val == 0:
            print(f"   ‚ö†Ô∏è  –í–Ω–∏–º–∞–Ω–∏–µ: –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ä–∞–≤–Ω—ã –Ω—É–ª—é")
        
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏: (–∫–∞–Ω–∞–ª—ã, –≤—Ä–µ–º—è)
        print(f"   üîß –ü—Ä–æ–≤–µ—Ä—è—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å...")
        
        if audio_tensor.ndim == 1:
            # (–≤—Ä–µ–º—è) -> (1, –≤—Ä–µ–º—è) - –º–æ–Ω–æ –∑–≤—É–∫
            audio_tensor = audio_tensor.unsqueeze(0)
            print(f"   üîÑ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ: 1D -> 2D, –Ω–æ–≤—ã–π shape: {audio_tensor.shape}")
        elif audio_tensor.ndim == 2:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é
            if audio_tensor.shape[0] > audio_tensor.shape[1] and audio_tensor.shape[0] > 10:
                # –í–æ–∑–º–æ–∂–Ω–æ (–≤—Ä–µ–º—è, –∫–∞–Ω–∞–ª—ã) -> (–∫–∞–Ω–∞–ª—ã, –≤—Ä–µ–º—è)
                audio_tensor = audio_tensor.transpose(0, 1)
                print(f"   üîÑ –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: –Ω–æ–≤—ã–π shape: {audio_tensor.shape}")
        elif audio_tensor.ndim == 3:
            # (batch, –∫–∞–Ω–∞–ª—ã, –≤—Ä–µ–º—è) -> (–∫–∞–Ω–∞–ª—ã, –≤—Ä–µ–º—è)
            if audio_tensor.shape[0] == 1:
                audio_tensor = audio_tensor.squeeze(0)
                print(f"   üîÑ –£–¥–∞–ª–µ–Ω batch dimension: –Ω–æ–≤—ã–π shape: {audio_tensor.shape}")
            else:
                raise ValueError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è 3D —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {audio_tensor.shape}")
        else:
            raise ValueError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Ç–µ–Ω–∑–æ—Ä–∞: {audio_tensor.ndim}")
        
        print(f"   üìê –§–∏–Ω–∞–ª—å–Ω—ã–π shape: {audio_tensor.shape}")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if speed != 1.0:
            try:
                from torchaudio.transforms import Speed
                print(f"   üèéÔ∏è  –ü—Ä–∏–º–µ–Ω—è—é –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏: {speed}x")
                speed_transform = Speed(
                    orig_freq=target_sample_rate,
                    factor=speed
                )
                audio_tensor = speed_transform(audio_tensor)
                print(f"   üìê Shape –ø–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏: {audio_tensor.shape}")
            except ImportError:
                print(f"   ‚ö†Ô∏è  torchaudio.transforms –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞—é –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏")
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        temp_dir = '/app/temp_audio'
        os.makedirs(temp_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
        filename = f"tts_{language}_{speaker}_{timestamp}.wav"
        filepath = os.path.join(temp_dir, filename)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ –≤ —Ñ–∞–π–ª
        print(f"   üíæ –°–æ—Ö—Ä–∞–Ω—è—é –∞—É–¥–∏–æ –≤ —Ñ–∞–π–ª: {filepath}")
        
        try:
            # –°–ø–æ—Å–æ–± 1: –ò—Å–ø–æ–ª—å–∑—É–µ–º torchaudio.save
            torchaudio.save(
                filepath,
                audio_tensor,
                target_sample_rate,
                encoding="PCM_S",
                bits_per_sample=16
            )
            print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —á–µ—Ä–µ–∑ torchaudio")
            
        except Exception as e1:
            print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ torchaudio.save: {e1}")
            
            try:
                # –°–ø–æ—Å–æ–± 2: –ò—Å–ø–æ–ª—å–∑—É–µ–º wave –º–æ–¥—É–ª—å –Ω–∞–ø—Ä—è–º—É—é
                import wave
                import numpy as np
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy
                audio_np = audio_tensor.squeeze().numpy()
                
                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è 16-bit PCM
                if audio_np.dtype != np.float32:
                    audio_np = audio_np.astype(np.float32)
                
                # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ 16-bit PCM
                int16_max = 32767
                audio_np = (audio_np * int16_max).astype(np.int16)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ—Ä–µ–∑ wave
                with wave.open(filepath, 'w') as wav_file:
                    wav_file.setnchannels(1)  # –º–æ–Ω–æ
                    wav_file.setsampwidth(2)  # 16-bit
                    wav_file.setframerate(target_sample_rate)
                    wav_file.writeframes(audio_np.tobytes())
                
                print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —á–µ—Ä–µ–∑ wave –º–æ–¥—É–ª—å")
                
            except Exception as e2:
                print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ wave.save: {e2}")
                
                try:
                    # –°–ø–æ—Å–æ–± 3: –ò—Å–ø–æ–ª—å–∑—É–µ–º scipy –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
                    import scipy.io.wavfile
                    
                    audio_np = audio_tensor.squeeze().numpy()
                    int16_max = 32767
                    audio_np = (audio_np * int16_max).astype(np.int16)
                    
                    scipy.io.wavfile.write(filepath, target_sample_rate, audio_np)
                    print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —á–µ—Ä–µ–∑ scipy")
                    
                except ImportError:
                    print(f"   ‚ùå scipy –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                    raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª –Ω–∏–∫–∞–∫–∏–º –º–µ—Ç–æ–¥–æ–º")
                except Exception as e3:
                    print(f"   ‚ùå –û—à–∏–±–∫–∞ scipy.save: {e3}")
                    raise
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω
        if os.path.exists(filepath):
            filesize = os.path.getsize(filepath) / 1024
            print(f"   ‚úÖ –§–∞–π–ª —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ!")
            print(f"   üìÅ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {filesize:.1f} KB")
        else:
            raise ValueError(f"–§–∞–π–ª –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω: {filepath}")
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        generation_time = time.time() - start_time
        audio_duration = audio_tensor.shape[-1] / target_sample_rate
        
        print(f"\n‚úÖ –ê—É–¥–∏–æ —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ!")
        print(f"   ‚è±Ô∏è  –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {generation_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"   üïí –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ: {audio_duration:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"   üìÅ –§–∞–π–ª: {filepath}")
        print(f"   üìä –†–∞–∑–º–µ—Ä: {filesize:.1f} KB")
        
        return filepath
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {str(e)}")
        import traceback
        traceback.print_exc()
        raise

# ========== API –ú–ê–†–®–†–£–¢–´ ==========

@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º"""
    try:
        return render_template('index.html')
    except Exception as e:
        return jsonify({
            'service': 'Zindaki TTS Service',
            'version': '2.0',
            'status': 'running',
            'endpoints': {
                '/': 'GET - –≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞',
                '/api/tts': 'POST - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ',
                '/api/health': 'GET - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è',
                '/api/voices': 'GET - —Å–ø–∏—Å–æ–∫ –≥–æ–ª–æ—Å–æ–≤',
                '/api/test': 'GET - —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å',
                '/api/debug': 'GET - –æ—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è',
                '/api/status/<job_id>': 'GET - —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏'
            },
            'timestamp': datetime.now().isoformat()
        })

@app.route('/api/tts', methods=['POST'])
def tts_request():
    """
    –û—Å–Ω–æ–≤–Ω–æ–π endpoint –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ TTS
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        data = request.get_json()
        if not data:
            return jsonify({'error': 'No JSON data provided'}), 400
        
        req = TTSRequest(**data)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
        if len(req.text) == 0:
            return jsonify({'error': 'Text cannot be empty'}), 400
        
        if len(req.text) > 10000:
            return jsonify({
                'error': f'Text too long ({len(req.text)} chars). Max is 10000.'
            }), 400
        
        print(f"\nüì® –ü–æ–ª—É—á–µ–Ω TTS –∑–∞–ø—Ä–æ—Å:")
        print(f"   üåê –Ø–∑—ã–∫: {req.language}")
        print(f"   üó£Ô∏è  –ì–æ–ª–æ—Å: {req.speaker}")
        print(f"   üìù –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(req.text)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   üèéÔ∏è  –°–∫–æ—Ä–æ—Å—Ç—å: {req.speed}x")
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
        job = queue.enqueue(
            generate_audio,
            args=(req.text, req.language, req.speaker, req.sample_rate, req.speed),
            job_timeout=300,
            result_ttl=3600,
            failure_ttl=1800
        )
        
        return jsonify({
            'job_id': job.get_id(),
            'status': 'queued',
            'message': '–ó–∞–¥–∞—á–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –æ—á–µ—Ä–µ–¥—å –æ–±—Ä–∞–±–æ—Ç–∫–∏',
            'estimated_time': '5-30 —Å–µ–∫—É–Ω–¥',
            'models_loaded': list(tts_models.keys()),
            'timestamp': datetime.now().isoformat()
        }), 202
        
    except ValidationError as e:
        return jsonify({
            'error': 'Invalid request data',
            'details': e.errors()
        }), 400
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ tts_request: {str(e)}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/status/<job_id>', methods=['GET'])
def get_job_status(job_id):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏ –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
    try:
        job = Job.fetch(job_id, connection=redis_conn)
        
        if job.is_finished:
            result = job.result
            
            if not result or not os.path.exists(result):
                return jsonify({'error': 'No audio file generated'}), 500
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
            if not result.endswith('.wav'):
                print(f"‚ö†Ô∏è  –§–∞–π–ª –∏–º–µ–µ—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ: {result}")
                # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –µ—Å–ª–∏ —ç—Ç–æ .wav.json
                if result.endswith('.wav.json'):
                    new_result = result.replace('.wav.json', '.wav')
                    if os.path.exists(new_result):
                        result = new_result
                    else:
                        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ WAV —Ñ–∞–π–ª
                        base_name = os.path.splitext(result)[0]
                        wav_file = base_name + '.wav'
                        if os.path.exists(wav_file):
                            result = wav_file
                        else:
                            raise ValueError(f"WAV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è {result}")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
            response = send_file(
                result,
                mimetype='audio/wav',
                as_attachment=True,
                download_name=f'tts_{job_id}.wav'
            )
            
            # –û—á–∏—Å—Ç–∫–∞ —Ñ–∞–π–ª–∞ –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏
            @response.call_on_close
            def cleanup():
                try:
                    if os.path.exists(result):
                        os.remove(result)
                        print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {result}")
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
            
            return response
            
        elif job.is_failed:
            error_msg = str(job.exc_info) if job.exc_info else 'Unknown error'
            return jsonify({
                'error': 'Job failed',
                'details': error_msg,
                'status': 'failed'
            }), 500
            
        else:
            # –ó–∞–¥–∞—á–∞ –µ—â–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è
            return jsonify({
                'status': job.get_status(),
                'position': job.get_position() if hasattr(job, 'get_position') else 'unknown',
                'models_loaded': list(tts_models.keys()),
                'timestamp': datetime.now().isoformat()
            }), 200
            
    except Exception as e:
        return jsonify({'error': f'Job not found: {str(e)}'}), 404

@app.route('/api/health', methods=['GET'])
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ Redis
        redis_conn.ping()
        
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
        if not tts_models:
            try:
                load_tts_model('ru', 'baya')
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –ø—Ä–∏ health check: {e}")
        
        return jsonify({
            'status': 'healthy',
            'service': 'zindaki-tts-service',
            'redis': 'connected',
            'models_loaded': list(tts_models.keys()),
            'models_count': len(tts_models),
            'torch_version': torch.__version__,
            'torchaudio_version': torchaudio.__version__,
            'cuda_available': torch.cuda.is_available(),
            'python_version': sys.version.split()[0],
            'uptime': str(datetime.now() - startup_time),
            'cache_dir': os.environ.get('TORCH_HOME'),
            'timestamp': datetime.now().isoformat()
        }), 200
        
    except Exception as e:
        return jsonify({
            'status': 'unhealthy',
            'error': str(e),
            'models_loaded': list(tts_models.keys()),
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/api/voices', methods=['GET'])
def get_available_voices():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤"""
    # –û—Å–Ω–æ–≤–Ω—ã–µ –≥–æ–ª–æ—Å–∞
    voices_info = {
        'ru': [
            {'id': 'baya', 'name': '–ë–∞–π—è', 'gender': 'female', 'description': '–ß–∏—Å—Ç—ã–π –∂–µ–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å'},
            {'id': 'kseniya', 'name': '–ö—Å–µ–Ω–∏—è', 'gender': 'female', 'description': '–ú—è–≥–∫–∏–π –∂–µ–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å'},
            {'id': 'aidar', 'name': '–ê–π–¥–∞—Ä', 'gender': 'male', 'description': '–ú—É–∂—Å–∫–æ–π –≥–æ–ª–æ—Å'},
            {'id': 'irina', 'name': '–ò—Ä–∏–Ω–∞', 'gender': 'female', 'description': '–ñ–µ–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å'},
            {'id': 'natasha', 'name': '–ù–∞—Ç–∞—à–∞', 'gender': 'female', 'description': '–ñ–µ–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å'},
            {'id': 'ruslan', 'name': '–†—É—Å–ª–∞–Ω', 'gender': 'male', 'description': '–ú—É–∂—Å–∫–æ–π –≥–æ–ª–æ—Å'},
            {'id': 'xenia', 'name': '–ö—Å–µ–Ω–∏—è 2', 'gender': 'female', 'description': '–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∂–µ–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å'},
            {'id': 'random', 'name': '–°–ª—É—á–∞–π–Ω—ã–π', 'gender': 'random', 'description': '–°–ª—É—á–∞–π–Ω—ã–π –≥–æ–ª–æ—Å'}
        ],
        'en': [
            {'id': 'en_0', 'name': 'Amy', 'gender': 'female', 'description': 'English female voice'},
            {'id': 'en_1', 'name': 'Eric', 'gender': 'male', 'description': 'English male voice'},
            {'id': 'en_2', 'name': 'Kyle', 'gender': 'male', 'description': 'English male voice'},
            {'id': 'en_3', 'name': 'Lucy', 'gender': 'female', 'description': 'English female voice'},
            {'id': 'en_4', 'name': 'Nancy', 'gender': 'female', 'description': 'English female voice'},
            {'id': 'en_5', 'name': 'Grace', 'gender': 'female', 'description': 'English female voice'},
        ]
    }
    
    return jsonify({
        'all_voices': voices_info,
        'loaded_voices': list(tts_models.keys()),
        'total_loaded': len(tts_models),
        'speaker_mapping': {k: list(v.keys())[:5] for k, v in SPEAKER_MAPPING.items()},
        'timestamp': datetime.now().isoformat()
    })

@app.route('/api/test', methods=['GET'])
def test_endpoint():
    """–¢–µ—Å—Ç–æ–≤—ã–π endpoint –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç—ã —Å–µ—Ä–≤–∏—Å–∞"""
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å
        model_info = load_tts_model('ru', 'baya')
        
        # –¢–µ—Å—Ç–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        test_text = "–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ —Ç–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ TTS —Å–µ—Ä–≤–∏—Å–∞. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ."
        
        print(f"üß™ –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: {test_text}")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ
        audio_result = model_info['apply_tts'](
            texts=[test_text],
            model=model_info['model'],
            sample_rate=model_info['sample_rate'],
            symbols=model_info['symbols'],
            device=model_info['device']
        )
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if isinstance(audio_result, list):
            audio = audio_result[0]
            result_type = f"list[{len(audio_result)}]"
            if isinstance(audio, torch.Tensor):
                audio_shape = str(audio.shape)
                audio_dtype = str(audio.dtype)
            else:
                audio_shape = f"type: {type(audio)}"
                audio_dtype = "N/A"
        else:
            audio = audio_result
            result_type = str(type(audio_result))
            audio_shape = str(audio.shape) if hasattr(audio, 'shape') else 'no shape'
            audio_dtype = str(audio.dtype) if hasattr(audio, 'dtype') else 'no dtype'
        
        # –ü—Ä–æ–±—É–µ–º —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        temp_dir = '/app/temp_audio'
        os.makedirs(temp_dir, exist_ok=True)
        test_file = os.path.join(temp_dir, 'test_output.wav')
        
        if isinstance(audio, torch.Tensor):
            torchaudio.save(test_file, audio.unsqueeze(0) if audio.ndim == 1 else audio, 
                          model_info['sample_rate'])
            file_exists = os.path.exists(test_file)
            if file_exists:
                os.remove(test_file)
        else:
            file_exists = False
        
        return jsonify({
            'success': True,
            'message': 'TTS —Å–µ—Ä–≤–∏—Å —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ',
            'result_type': result_type,
            'audio_shape': audio_shape,
            'audio_dtype': audio_dtype,
            'sample_rate': model_info['sample_rate'],
            'model_loaded': True,
            'correct_speaker': model_info['correct_speaker'],
            'models_in_cache': list(tts_models.keys()),
            'test_file_saved': file_exists,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–µ —É–¥–∞–ª—Å—è: {e}")
        
        return jsonify({
            'success': False,
            'error': str(e),
            'error_details': error_details[:500],
            'models_in_cache': list(tts_models.keys()),
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/api/debug', methods=['GET'])
def debug_info():
    """–û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"""
    import numpy as np
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    templates_dir = '/app/templates'
    temp_dir = '/app/temp_audio'
    
    template_files = []
    if os.path.exists(templates_dir):
        template_files = os.listdir(templates_dir)
    
    temp_files = []
    if os.path.exists(temp_dir):
        temp_files = os.listdir(temp_dir)
    
    return jsonify({
        'torch_version': torch.__version__,
        'torchaudio_version': torchaudio.__version__,
        'python_version': sys.version,
        'environment': {
            'TORCH_HOME': os.environ.get('TORCH_HOME'),
            'HF_HOME': os.environ.get('HF_HOME'),
            'XDG_CACHE_HOME': os.environ.get('XDG_CACHE_HOME'),
            'PYTHONPATH': os.environ.get('PYTHONPATH')
        },
        'directories': {
            'templates_exists': os.path.exists(templates_dir),
            'templates_files': template_files,
            'temp_audio_exists': os.path.exists(temp_dir),
            'temp_files_count': len(temp_files),
            'temp_files_sample': temp_files[:5] if temp_files else []
        },
        'models_loaded': list(tts_models.keys()),
        'model_details': {
            k: {
                'correct_speaker': v['correct_speaker'],
                'sample_rate': v['sample_rate'],
                'loaded_at': v['loaded_at']
            } for k, v in tts_models.items()
        },
        'redis_connected': redis_conn.ping() if redis_conn else False,
        'numpy_version': np.__version__,
        'timestamp': datetime.now().isoformat()
    })

@app.route('/api/load-model/<language>/<speaker>', methods=['POST'])
def load_model_endpoint(language, speaker):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    try:
        model_key = f"{language}_{speaker}"
        
        if model_key in tts_models:
            return jsonify({
                'message': 'Model already loaded',
                'model_key': model_key,
                'loaded_at': tts_models[model_key]['loaded_at']
            })
        
        model_info = load_tts_model(language, speaker)
        
        return jsonify({
            'message': 'Model loaded successfully',
            'model_key': model_key,
            'correct_speaker': model_info['correct_speaker'],
            'sample_rate': model_info['sample_rate'],
            'example_text': model_info['example_text'][:100],
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/cleanup', methods=['POST'])
def cleanup_endpoint():
    """–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    try:
        temp_dir = '/app/temp_audio'
        if not os.path.exists(temp_dir):
            return jsonify({'message': 'Temp directory does not exist', 'deleted': 0})
        
        deleted_count = 0
        for filename in os.listdir(temp_dir):
            filepath = os.path.join(temp_dir, filename)
            try:
                if os.path.isfile(filepath):
                    os.remove(filepath)
                    deleted_count += 1
            except:
                pass
        
        return jsonify({
            'message': f'Deleted {deleted_count} temporary files',
            'deleted': deleted_count,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ========== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ==========

def cleanup_temp_files():
    """–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    temp_dir = '/app/temp_audio'
    if os.path.exists(temp_dir):
        try:
            count = 0
            for filename in os.listdir(temp_dir):
                file_path = os.path.join(temp_dir, filename)
                if os.path.isfile(file_path):
                    try:
                        # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã (—Å—Ç–∞—Ä—à–µ 1 —á–∞—Å–∞)
                        if time.time() - os.path.getctime(file_path) > 3600:
                            os.remove(file_path)
                            count += 1
                    except:
                        pass
            if count > 0:
                print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {count} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —Å—Ç–∞—Ä—à–µ 1 —á–∞—Å–∞")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")

def periodic_cleanup():
    """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    while True:
        time.sleep(3600)  # –ö–∞–∂–¥—ã–π —á–∞—Å
        cleanup_temp_files()

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ—á–∏—Å—Ç–∫—É –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
atexit.register(cleanup_temp_files)

# ========== –ó–ê–ü–£–°–ö –°–ï–†–í–ò–°–ê ==========

if __name__ == '__main__':
    print("\n" + "=" * 70)
    print("üéµ ZINDAKI TTS SERVICE - –°–µ—Ä–≤–∏—Å –æ–∑–≤—É—á–∫–∏ –¥–ª—è –æ–Ω–ª–∞–π–Ω-—à–∫–æ–ª—ã")
    print("=" * 70)
    print(f"üìÖ –î–∞—Ç–∞ –∑–∞–ø—É—Å–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üêç Python –≤–µ—Ä—Å–∏—è: {sys.version.split()[0]}")
    print(f"üî• PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
    print(f"üéµ TorchAudio –≤–µ—Ä—Å–∏—è: {torchaudio.__version__}")
    print(f"üìÅ –ö—ç—à –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.environ.get('TORCH_HOME')}")
    print(f"üîó Redis: {os.getenv('REDIS_HOST', 'tts-redis')}:{os.getenv('REDIS_PORT', 6379)}")
    print("=" * 70)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫—É—é –æ—á–∏—Å—Ç–∫—É –≤ —Ñ–æ–Ω–æ–≤–æ–º –ø–æ—Ç–æ–∫–µ
    cleanup_thread = threading.Thread(target=periodic_cleanup, daemon=True)
    cleanup_thread.start()
    
    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏
    print("\n‚è≥ –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏...")
    try:
        load_tts_model('ru', 'baya')
        print(f"‚úÖ –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: ru_baya")
        print(f"   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≥–æ–ª–æ—Å: {tts_models['ru_baya']['correct_speaker']}")
        print(f"   –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: {tts_models['ru_baya']['sample_rate']} Hz")
        print(f"   –ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞: {tts_models['ru_baya']['example_text'][:50]}...")
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ: {e}")
        print("   –ú–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ")
    
    # –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
    print("\nüöÄ –ó–∞–ø—É—Å–∫ Flask —Å–µ—Ä–≤–µ—Ä–∞...")
    print(f"üåê –î–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É: http://0.0.0.0:5000")
    print(f"üìö API –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ: http://0.0.0.0:5000/api/health")
    print("=" * 70)
    
    app.run(
        host='0.0.0.0',
        port=5000,
        debug=False,
        threaded=True,
        use_reloader=False
    )